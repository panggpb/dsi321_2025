{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e53e2377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow.parquet as pq\n",
    "import s3fs\n",
    "import time\n",
    "from zoneinfo import ZoneInfo\n",
    "from datetime import timedelta, datetime\n",
    "\n",
    "\n",
    "# Set up environments of LakeFS\n",
    "lakefs_endpoint = os.getenv(\"LAKEFS_ENDPOINT\", \"http://lakefs-dev:8000\")\n",
    "ACCESS_KEY = 'access_key'\n",
    "SECRET_KEY = 'secret_key'\n",
    "\n",
    "# Setting S3FileSystem for access LakeFS\n",
    "fs = s3fs.S3FileSystem(\n",
    "    key=ACCESS_KEY,\n",
    "    secret=SECRET_KEY,\n",
    "    client_kwargs={'endpoint_url': lakefs_endpoint}\n",
    ")\n",
    "\n",
    "def load_data():\n",
    "    lakefs_path = \"s3://dsi321-record-air-quality/main/airquality.parquet/year=2025\"\n",
    "    data_list = fs.glob(f\"{lakefs_path}/*/*/*/*\")\n",
    "    df_all = pd.concat([pd.read_parquet(f\"s3://{path}\", filesystem=fs) for path in data_list], ignore_index=True)\n",
    "    df_all['lat'] = pd.to_numeric(df_all['lat'], errors='coerce')\n",
    "    df_all['long'] = pd.to_numeric(df_all['long'], errors='coerce')\n",
    "    df_all['year'] = df_all['year'].astype(\"int64\")\n",
    "    df_all['month'] = df_all['month'].astype(\"int64\")\n",
    "    df_all['day'] = df_all['month'].astype(\"int64\")\n",
    "    df_all['hour'] = df_all['month'].astype(\"int64\")\n",
    "    df_all.drop_duplicates(inplace=True)\n",
    "    df_all['PM25.aqi'] = df_all['PM25.aqi'].mask(df_all['PM25.aqi'] < 0, pd.NA)\n",
    "    # Fill value \"Previous Record\" Group By stationID\n",
    "    df_all['PM25.aqi'] = df_all.groupby('stationID')['PM25.aqi'].transform(lambda x: x.ffill())\n",
    "    return df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f13e11fa-41d4-4441-9fb6-3ded7a6f16fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f4b4ce48-38c2-48ec-946f-4c6068f8f855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function load_data at 0xffff281e3c40>\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2c90c4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# เปลี่ยน data types กันด้วยนะ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c35ed9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aa5e60aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✨ No new partitions to add.\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "existing_parts = set()\n",
    "paths = glob(\"data2.parquet/year=*/month=*/day=*/hour=*\")\n",
    "\n",
    "for path in paths:\n",
    "    parts = path.split(os.sep)\n",
    "    part_dict = {p.split(\"=\")[0]: int(p.split(\"=\")[1]) for p in parts if \"=\" in p}\n",
    "    key = (part_dict[\"year\"], part_dict[\"month\"], part_dict[\"day\"], part_dict[\"hour\"])\n",
    "    existing_parts.add(key)\n",
    "\n",
    "# ✅ 3. กรองเฉพาะพาร์ทิชันใหม่\n",
    "df[\"partition_key\"] = list(zip(df[\"year\"], df[\"month\"], df[\"day\"], df[\"hour\"]))\n",
    "df_new = df[~df[\"partition_key\"].isin(existing_parts)].drop(columns=[\"partition_key\"])\n",
    "\n",
    "# ✅ 4. เขียนเฉพาะพาร์ทิชันใหม่เข้า data2.parquet\n",
    "if not df_new.empty:\n",
    "    import pyarrow as pa\n",
    "    import pyarrow.dataset as ds\n",
    "    table = pa.Table.from_pandas(df_new)\n",
    "    ds.write_dataset(\n",
    "        table,\n",
    "        base_dir=\"data2.parquet\",\n",
    "        format=\"parquet\",\n",
    "        partitioning=[\"year\", \"month\", \"day\", \"hour\"],\n",
    "        existing_data_behavior=\"overwrite_or_ignore\"\n",
    "    )\n",
    "    print(f\"✅ Added {len(df_new)} new records to data2.parquet\")\n",
    "else:\n",
    "    print(\"✨ No new partitions to add.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "74fde266-0ce3-4891-8200-775b080c06b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ข้อมูลทั้งหมดใน df:        year  month  day  hour\n",
      "0      2025      5   15    16\n",
      "374    2025      5   15    17\n",
      "561    2025      5   15    18\n",
      "748    2025      5   15    19\n",
      "935    2025      5   15    20\n",
      "...     ...    ...  ...   ...\n",
      "13058  2025      5   18     5\n",
      "13244  2025      5   18     6\n",
      "13430  2025      5   18     7\n",
      "13616  2025      5   18     8\n",
      "13802  2025      5   18     9\n",
      "\n",
      "[67 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"ข้อมูลทั้งหมดใน df:\", df[[\"year\", \"month\", \"day\", \"hour\"]].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f45dde1-68a1-4ab5-a940-d6bade8693aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
